{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPIN (Pre-)Workshop: Python & Obspy Crash Course\n",
    "\n",
    "This repository contains material (notebooks and data) for the Python & Obspy crash course that will be held on 2021-11-18/19 as part of the SPIN ([spin-itn.eu](https://spin-itn.eu)) project.\n",
    "\n",
    "## Questionnaire results (n=12)\n",
    "\n",
    "question | mean | std | min\n",
    "|---|---|--|---|\n",
    "|programming|6.2|1.6|4|\n",
    "|python|6.2|1.9|4|\n",
    "|numpy/scipy|6.5|2.2|3|\n",
    "|obspy|5|3.2|1|\n",
    "\n",
    "## Structure\n",
    "\n",
    "**Part A (Python tips & tricks)**: The questionnaire has shown that all of you have at least some experience with Python. Therefore, I will not go over the **very** basics and will instead present a few helpful concepts, tips and tricks that you may not yet be aware of.\n",
    "\n",
    "**Part B (Obspy)**: Some of you have experience with obspy, while others do not. I will present the basic ideas and data structures of obspy. Then we will download some data, and you'll have time to experiment with this yourself.\n",
    "\n",
    "**What this course will not cover**: The basics of Python (how to define numbers, functions, etc. ). More advanced topics, such optimization of code for performance or parallelisation; code architecture; topics related to logistics, e.g., accessing and running code on a server; managing python environments\n",
    "\n",
    "## Some useful resources:\n",
    "\n",
    "- [seismo-live.org](http://seismo-live.org/): Collection of jupyter notebooks on various seismological topics.\n",
    "- [obspy documentation](https://docs.obspy.org): Obspy's documentation, including tutorials.\n",
    "- [cartopy documentation](https://scitools.org.uk/cartopy/docs/latest/): Cartopy's documentation, including a gallery (very useful).\n",
    "- MIT's [\"Missing Semester\"](https://www.youtube.com/c/MissingSemester): Introductory lectures on the logistics surrounding programming, such as terminals, code editors, git, debugging and profiling, and others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Python tips & tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add the bad guy from 'Nightmare on Elm street' to the list. Then replace him with Hannibal Lecter.\n",
    "bad_guys = [\"Michael Myers\", \"Jason Voorhees\"]\n",
    "print(bad_guys)\n",
    "\n",
    "bad_guys.append(\"Freddy Krueger\")\n",
    "print(bad_guys)\n",
    "\n",
    "bad_guys[-1] = \"Hannibal Lecter\"\n",
    "print(bad_guys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do the same with a tuple\n",
    "bad_guys = (\"Michael Myers\", \"Jason Voorhees\")\n",
    "print(bad_guys)\n",
    "\n",
    "bad_guys = \"Michael Myers\", \"Jason Voorhees\"\n",
    "print(bad_guys)\n",
    "\n",
    "# strings - also immutable (but sneaky behaviour)\n",
    "name = bad_guys[0]\n",
    "print(name, hex(id(name)))\n",
    "\n",
    "name = name[:-1] + \"z\"\n",
    "print(name, hex(id(name)))\n",
    "\n",
    "name = \"Michael Myers\"\n",
    "print(name, hex(id(name)))\n",
    "\n",
    "# hashing - dictionaries\n",
    "dictionary = {\"Jason Voorhess\": 1946}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copies of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a new list with the entries of bad_guys and alter it\n",
    "bad_guys = [\"Michael Myers\", \"Jason Voorhees\", \"Hannibal Lecter\"].copy()\n",
    "bad_guys_two = bad_guys\n",
    "print(bad_guys_two)\n",
    "bad_guys_two[0] = \"\"\n",
    "\n",
    "# changing the \"new\" list changes the old one, too.\n",
    "print(bad_guys)\n",
    "print(bad_guys_two)\n",
    "\n",
    "# they are the same object. list_2 = list_1 creates a new _pointer_, not a new list.\n",
    "print(hex(id(bad_guys)))\n",
    "print(hex(id(bad_guys_two)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For loops for non-Pythonistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print each name in the list and its index in a new line.\n",
    "bad_guys = [\"Michael Myers\", \"Jason Voorhees\", \"Hannibal Lecter\"]\n",
    "\n",
    "# range(len())\n",
    "for idx in range(len(bad_guys)):\n",
    "    print(idx, bad_guys[idx])\n",
    "\n",
    "# use for-each logic and increment manually\n",
    "idx = 0\n",
    "for bad_guy in bad_guys:\n",
    "    print(idx, bad_guy)\n",
    "    idx += 1\n",
    "\n",
    "# the pythonic way\n",
    "for idx, bad_guy in enumerate(bad_guys):\n",
    "    print(idx, bad_guy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## itertools and generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print all possible combination pairs of bad guys\n",
    "bad_guys = [\"Michael Myers\", \"Jason Voorhees\", \"Hannibal Lecter\"]\n",
    "\n",
    "# naive approach - (duplicates)\n",
    "for bad_guy1 in bad_guys:\n",
    "    for bad_guy2 in bad_guys:\n",
    "        if bad_guy1 != bad_guy2:\n",
    "            print(bad_guy1, bad_guy2)\n",
    "\n",
    "# enumerate approach - works\n",
    "for idx1, bad_guy1 in enumerate(bad_guys):\n",
    "    for idx2, bad_guy2 in enumerate(bad_guys):\n",
    "        if idx2 > idx1:\n",
    "            print(bad_guy1, bad_guy2)\n",
    "\n",
    "# itertools approach - convenient, fast, easy\n",
    "from itertools import combinations\n",
    "for bad_guy1, bad_guy2 in combinations(bad_guys, 2):\n",
    "    print(bad_guy1, bad_guy2)\n",
    "\n",
    "# other itertools iterator exist\n",
    "from itertools import product\n",
    "for bad_guy1, bad_guy2 in product(bad_guys, bad_guys):\n",
    "    print(bad_guy1, bad_guy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print all possible combination pairs of bad guys, but only if a) Hannibal Lecter is one of them\n",
    "# easy enough\n",
    "for bad_guy1, bad_guy2 in combinations(bad_guys, 2):\n",
    "    if \"Hannibal Lecter\" in [bad_guy1, bad_guy2]:\n",
    "        # following code is now already indented 2 times\n",
    "        print(bad_guy1, bad_guy2)\n",
    "\n",
    "# define a generator\n",
    "def bad_guy_pairs_generator(bad_guys):\n",
    "    for bad_guy1, bad_guy2 in combinations(bad_guys, 2):\n",
    "        if \"Hannibal Lecter\" in [bad_guy1, bad_guy2]:\n",
    "            yield bad_guy1, bad_guy2\n",
    "\n",
    "for bad_guy1, bad_guy2 in bad_guy_pairs_generator(bad_guys):\n",
    "    print(bad_guy1, bad_guy2)\n",
    "\n",
    "generator = bad_guy_pairs_generator(bad_guys)\n",
    "print(generator)\n",
    "# demonstrate its behaviour - list()\n",
    "print(list(generator))\n",
    "# demonstrate its behaviour - next()\n",
    "generator = bad_guy_pairs_generator(bad_guys)\n",
    "print(next(generator))\n",
    "print(next(generator))\n",
    "print(list(generator))\n",
    "\n",
    "# real world case -- imagine a parameter study, e.g., strike/dip/rake of an earthquake\n",
    "strikes = range(0, 360)\n",
    "dips = range(0, 90)\n",
    "rakes = range(-180, 180)\n",
    "for strike in strikes:\n",
    "    for dip in dips:\n",
    "        for rake in rakes:\n",
    "            # compute synthetic waveforms\n",
    "            # estimate fit w/ recorded waveforms\n",
    "            # save fit\n",
    "            pass\n",
    "\n",
    "def sdr_generator(strikes, dips, rakes):\n",
    "    for strike in strikes:\n",
    "        for dip in dips:\n",
    "            for rake in rakes:\n",
    "                yield strike, dip, rake\n",
    "\n",
    "for strike, dip, rake in sdr_generator(strikes, dips, rakes):\n",
    "    # do something with strike, dip, rake\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tracking progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: loop over all bad guys, do something that takes long with each, and estimate the time it takes\n",
    "bad_guys = [\"Michael Myers\", \"Jason Voorhees\", \"Hannibal Lecter\"]\n",
    "\n",
    "from time import time, sleep\n",
    "starttime = time()\n",
    "for bad_guy in bad_guys:\n",
    "    sleep(1)\n",
    "print(time() - starttime)\n",
    "\n",
    "starttime = time()\n",
    "for bad_guy in bad_guys:\n",
    "    starttime_step = time()\n",
    "    sleep(1)\n",
    "    print(time() - starttime_step)\n",
    "print(time() - starttime)\n",
    "\n",
    "# conda install tqdm\n",
    "from tqdm import tqdm\n",
    "for bad_guy in tqdm(bad_guys):\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a new list that contains only each first name.\n",
    "bad_guys = [\"Michael Myers\", \"Jason Voorhees\", \"Hannibal Lecter\"]\n",
    "first_names = []\n",
    "for full_name in bad_guys:\n",
    "    first_name = full_name.split()[0]\n",
    "    first_names.append(first_name)\n",
    "print(first_names)\n",
    "\n",
    "# list comprehension\n",
    "first_names = [full_name.split()[0] for full_name in first_names]\n",
    "print(first_names)\n",
    "\n",
    "# list comprehension w/ if statement\n",
    "first_names = [full_name.split()[0] for full_name in first_names if \"Jason\" in full_name]\n",
    "print(first_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print each bad guy and his birthyear together. then save them.\n",
    "bad_guys = [\"Michael Myers\", \"Jason Voorhees\", \"Hannibal Lecter\"]\n",
    "birthyears = [1957, 1946, 1933]\n",
    "\n",
    "for idx, bad_guy in enumerate(bad_guys):\n",
    "    print(bad_guy, birthyears[idx])\n",
    "\n",
    "for bad_guy, birthyear in zip(bad_guys, birthyears):\n",
    "    print(bad_guy, birthyear)\n",
    "\n",
    "bad_guy_dict = {}\n",
    "for bad_guy, birthyear in zip(bad_guys, birthyears):\n",
    "    bad_guy_dict[bad_guy] = birthyear\n",
    "print(bad_guy_dict)\n",
    "\n",
    "# dict comprehension\n",
    "bad_guy_dict = {bad_guy: birthyear for bad_guy, birthyear in zip(bad_guys, birthyears)}\n",
    "print(bad_guy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print a statement like so for each bad guy:\n",
    "# \"Michael Myers was born in 1957\"\n",
    "bad_guys = [\"Michael Myers\", \"Jason Voorhees\", \"Hannibal Lecter\"]\n",
    "birthyears = [1957, 1946, 1933]\n",
    "\n",
    "for bad_guy in bad_guy_dict:\n",
    "    birthyear = bad_guy_dict[bad_guy]\n",
    "\n",
    "    # concatenation\n",
    "    # print(bad_guy + \" was born in \" + birthyear)\n",
    "    print(bad_guy + \" was born in \" + str(birthyear))\n",
    "\n",
    "    # %-style\n",
    "    print(\"%s was born in %d\" % (bad_guy, birthyear))\n",
    "    \n",
    "    # .format\n",
    "    print(\"{} was born in {}\".format(bad_guy, birthyear))\n",
    "    print(\"{1} was born in {0}\".format(birthyear, bad_guy))\n",
    "\n",
    "    # f-string / string-interpolation\n",
    "    print(f\"{bad_guy} was born in {birthyear}\")\n",
    "    print(f\"{bad_guy} was born in {birthyear:.2f}\")\n",
    "    print(f\"{bad_guy} was born in {birthyear:06d}\")\n",
    "\n",
    "    # new syntax in python 3.8, useful for debugging\n",
    "    print(f\"{bad_guy=}, {birthyear=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: assign the items of a list into individual variables.\n",
    "bad_guys = [\"Michael Myers\", \"Jason Voorhees\", \"Hannibal Lecter\"]\n",
    "print(bad_guys)\n",
    "\n",
    "michael = bad_guys[0]\n",
    "jason = bad_guys[1]\n",
    "hannibal = bad_guys[2]\n",
    "print(michael, jason, hannibal)\n",
    "\n",
    "michael, jason, hannibal = bad_guys\n",
    "print(michael, jason, hannibal)\n",
    "\n",
    "print(bad_guys)\n",
    "print(*bad_guys)\n",
    "\n",
    "# real world case -- see cartopy plotting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: extract the first and last height\n",
    "import numpy as np\n",
    "\n",
    "birthyears = [1957, 1946, 1933]\n",
    "birthyears_array = np.array(birthyears)\n",
    "\n",
    "print(birthyears[:])\n",
    "print(birthyears_array[:])\n",
    "\n",
    "# print(birthyears[[0, -1]])\n",
    "print(birthyears_array[[0, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a list of birthyear-and-height-lists, and make it an array\n",
    "heights = [2.01, 1.96, 1.73]\n",
    "bad_guy_properties = [\n",
    "    [1957, 2.01],\n",
    "    [1946, 1.96],\n",
    "    [1933, 1.73]\n",
    "    ]\n",
    "\n",
    "bad_guy_properties = list(zip(birthyears, heights))\n",
    "\n",
    "bad_guy_properties_array = np.array(bad_guy_properties)\n",
    "\n",
    "# numpy forces consistency of type for computational efficiency\n",
    "print(bad_guy_properties)\n",
    "print(bad_guy_properties_array)\n",
    "print(type(bad_guy_properties[0][0]))\n",
    "print(type(bad_guy_properties_array[0][0]))\n",
    "print(bad_guy_properties_array.astype(int))\n",
    "\n",
    "# slicing in ndarrays\n",
    "print(bad_guy_properties_array[0])\n",
    "print(bad_guy_properties_array[[0, -1]])\n",
    "print(bad_guy_properties_array[[0, -1], :])\n",
    "print(bad_guy_properties_array[[0, -1], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the mean height of all bad guys\n",
    "\n",
    "# if list is available, easy enough with built-in\n",
    "print(sum(heights) / len(heights))\n",
    "\n",
    "# if only bad_guy_properties is available, loop required\n",
    "total_height = 0\n",
    "for yr, height in bad_guy_properties:\n",
    "    total_height += height\n",
    "print(total_height / len(bad_guy_properties))\n",
    "\n",
    "# use numpy on bad_guy_properties \n",
    "print(np.mean(bad_guy_properties_array))\n",
    "print(np.mean(bad_guy_properties_array, axis=0))\n",
    "\n",
    "# real world case -- imagine you have 50 seismograms with 1000 samples and you want to stack them\n",
    "seismograms = np.random.uniform(-1, 1, size=[50, 1000])\n",
    "stacked_seismogram = np.mean(seismograms, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances on Earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the distances between their hometowns (film locations).\n",
    "bad_guys = [\"Michael Myers\", \"Jason Voorhees\", \"Hannibal Lecter\"]\n",
    "hometowns = [[-118.16, 34.12], [-74.94, 41.06], [11.26, 43.77]]\n",
    "\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from obspy.geodetics import gps2dist_azimuth\n",
    "\n",
    "for loc1, loc2 in combinations(hometowns, 2):\n",
    "    dist, az, baz = gps2dist_azimuth(\n",
    "        lat1=loc1[1], lon1=loc1[0], lat2=loc2[1], lon2=loc2[0]\n",
    "    )\n",
    "    print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the distances between their hometowns and print a string representing\n",
    "\n",
    "for (guy1, loc1), (guy2, loc2) in combinations(zip(bad_guys, hometowns), 2):\n",
    "    dist, az, baz = gps2dist_azimuth(\n",
    "        lat1=loc1[1], lon1=loc1[0], lat2=loc2[1], lon2=loc2[0]\n",
    "    )\n",
    "    print(f\"{guy1} and {guy2} are {dist}m apart.\")\n",
    "    print(f\"{guy1} and {guy2} are {dist:.1f}m apart.\")\n",
    "    print(f\"{guy1} and {guy2} are {dist/1000:.1f}km apart.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maps with cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot an orthographic map with each location and label them.\n",
    "bad_guys = [\"Michael Myers\", \"Jason Voorhees\", \"Hannibal Lecter\"]\n",
    "# [South Pasadena, CA], [Camp Crystal Lake, NY], [Florence, Italy]\n",
    "hometowns = np.array([[-118.16, 34.12], [-74.94, 41.06], [11.26, 43.77]])\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = ccrs.Orthographic(central_longitude=-45, central_latitude=30)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": transform})\n",
    "ax.set_global()\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.coastlines()\n",
    "# ax.scatter([hometowns[0, 0], hometowns[1, 0], hometowns[2, 0]], [hometowns[0, 1], hometowns[1, 1], hometowns[2, 1]], c=\"#E2001A\", transform=ccrs.PlateCarree(), zorder=2)\n",
    "# ax.scatter(hometowns[:, 0], hometowns[:, 1], c=\"#E2001A\", transform=ccrs.PlateCarree(), zorder=2)\n",
    "# ax.scatter(*hometowns, c=\"#E2001A\", transform=ccrs.PlateCarree(), zorder=2)\n",
    "print(hometowns)\n",
    "print(*hometowns)\n",
    "print(*hometowns.T)\n",
    "ax.scatter(*hometowns.T, c=\"#E2001A\", transform=ccrs.PlateCarree(), zorder=2)\n",
    "for hometown, bad_guy in zip(hometowns, bad_guys):\n",
    "    t = ax.text(*hometown, bad_guy, transform=ccrs.PlateCarree(), fontweight=\"bold\")\n",
    "    t.set_bbox(dict(facecolor=\"w\", alpha=.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Obspy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obspy: The building blocks (time, waveforms, metadata, events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time: UTCDateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time's precision depends on your system clock (usually 100hz, 50hz)\n",
    "from time import time\n",
    "print(time())\n",
    "\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "print(UTCDateTime())\n",
    "print(UTCDateTime(\"2011-03-11T05:46:23.2\"))\n",
    "print(UTCDateTime(\"2011-03-11T14:46:23.2+09:00\"))\n",
    "print(UTCDateTime(2011, 3, 11, 5, 46, 23, 2))\n",
    "print(UTCDateTime(1299822383.2))\n",
    "\n",
    "# addition\n",
    "starttime = UTCDateTime(1299822383.2)\n",
    "print(time + 3600)\n",
    "\n",
    "# subtraction\n",
    "print((UTCDateTime() - starttime) / (60*60*24*365))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waveforms: Stream / Trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[documentation](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.html)\n",
    "\n",
    "![](./images/Stream_Trace.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: read stream, explore some functions\n",
    "\n",
    "from obspy import read\n",
    "st = read(\"./data/IU.GRFO.mseed\")\n",
    "print(st)\n",
    "print(st[0])\n",
    "\n",
    "# basic plotting functionality\n",
    "st.plot()\n",
    "for tr in st:\n",
    "    print(tr)\n",
    "\n",
    "# trimming data\n",
    "# st.trim()\n",
    "\n",
    "# filtering data\n",
    "# st.filter()\n",
    "\n",
    "# resampling data\n",
    "# st.resample()\n",
    "\n",
    "# decimating data\n",
    "# st.decimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata: Inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[documentation](https://docs.obspy.org/packages/obspy.core.inventory.html)\n",
    "\n",
    "![](./images/Inventory.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: read inventory, explore\n",
    "\n",
    "from obspy import read_inventory\n",
    "inv = read_inventory(\"./data/IU.GRFO.xml\")\n",
    "print(inv)\n",
    "net = inv[0]\n",
    "sta = net[0]\n",
    "chn = sta[0]\n",
    "\n",
    "inv.plot()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events: Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[documentation](https://docs.obspy.org/packages/autogen/obspy.core.event.Catalog.html)\n",
    "\n",
    "![](./images/Event.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: read catalog, explore\n",
    "\n",
    "from obspy import read_events\n",
    "cat = read_events(\"./data/sumatra.quakeml\")\n",
    "print(cat)\n",
    "print(cat[0])\n",
    "\n",
    "cat.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obspy: downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Download waveforms, metadata, and event information for the 2004 Sumatra Earthquake\n",
    "\n",
    "from obspy.clients.fdsn import Client\n",
    "client = Client(\"IRIS\")\n",
    "\n",
    "cat = client.get_events(\n",
    "    starttime=UTCDateTime(\"2004-12-20\"),\n",
    "    endtime=UTCDateTime(\"2004-12-31\"),\n",
    "    minmagnitude=8.5\n",
    "    )\n",
    "\n",
    "print(cat)\n",
    "\n",
    "inv = client.get_stations(\n",
    "    starttime=UTCDateTime(\"2004-12-20\"),\n",
    "    endtime=UTCDateTime(\"2004-12-31\"),\n",
    "    network=\"IU\",\n",
    "    station=\"GRFO\",\n",
    "    # level=\"channels\"\n",
    "    level=\"response\"\n",
    "    )\n",
    "\n",
    "print(inv)\n",
    "\n",
    "st = client.get_waveforms(\n",
    "    network=\"IU\",\n",
    "    station=\"GRFO\",\n",
    "    location=\"*\",\n",
    "    channel=\"BH*\",\n",
    "    starttime=cat[0].origins[0].time,\n",
    "    endtime=cat[0].origins[0].time + 7200,\n",
    "    )\n",
    "\n",
    "print(st)\n",
    "\n",
    "# st.write(f\"./data/{st[0].stats.network}.{st[0].stats.station}.mseed\", format=\"mseed\")\n",
    "# inv.write(f\"./data/{st[0].stats.network}.{st[0].stats.station}.xml\", format=\"stationxml\")\n",
    "# cat.write(f\"./data/sumatra.quakeml\", format=\"quakeml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explore common errors when requesting data\n",
    "\n",
    "from obspy.clients.fdsn import Client\n",
    "client = Client(\"BGR\")\n",
    "st_fail = client.get_waveforms(\n",
    "    network=\"IU\",\n",
    "    station=\"GRFO\",\n",
    "    location=\"*\",\n",
    "    channel=\"BH*\",\n",
    "    starttime=cat[0].origins[0].time,\n",
    "    endtime=cat[0].origins[0].time + 7200,\n",
    "    )\n",
    "\n",
    "cat_fail = client.get_events(\n",
    "    starttime=UTCDateTime(\"2004-12-20\"),\n",
    "    endtime=UTCDateTime(\"2004-12-31\"),\n",
    "    minmagnitude=8.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obspy: exercise\n",
    "\n",
    "For the this exercise we will download some data from the Tohoku-Oki earthquake, cut out a certain time window around the first arrival and remove the instrument response from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download the necessary data / metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the following things:\n",
    "# - Event information about the Tohoku-Oki earthquake. Use the get_events() method of the client. A good provider of event data is the IRIS.\n",
    "# - Waveform information for a certain station. Choose your favorite one! If you have no preference, use II.BFO which is available for example from IRIS. Use the get_waveforms() method.\n",
    "# - Download the associated station/instrument information with the get_stations() method.\n",
    "\n",
    "from obspy.clients.fdsn import Client\n",
    "client = Client(\"IRIS\")\n",
    "\n",
    "cat = client.get_events(\n",
    "    starttime=UTCDateTime(\"2011-03-01\"),\n",
    "    endtime=UTCDateTime(\"2011-04-01\"),\n",
    "    minmagnitude=9)\n",
    "print(cat)\n",
    "\n",
    "st = client.get_waveforms(\n",
    "    network=\"II\",\n",
    "    station=\"BFO\",\n",
    "    location=\"*\",\n",
    "    channel=\"LH*\",\n",
    "    starttime=cat[0].origins[0].time,\n",
    "    endtime=cat[0].origins[0].time + 14400\n",
    "    )\n",
    "print(st)\n",
    "\n",
    "inv = client.get_stations(\n",
    "    starttime=cat[0].origins[0].time,\n",
    "    endtime=cat[0].origins[0].time + 14400,\n",
    "    network=\"II\",\n",
    "    station=\"BFO\",\n",
    "    location=\"*\",\n",
    "    channel=\"LH*\",\n",
    "    level=\"response\"\n",
    ")\n",
    "print(inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Determine the coordinates of the station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_location = inv[0][0].longitude, inv[0][0].latitude\n",
    "print(station_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Determine the coordinates of the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_location = cat[0].origins[0].longitude, cat[0].origins[0].latitude\n",
    "print(event_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Calculate distance of event and station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.geodetics import gps2dist_azimuth\n",
    "\n",
    "dist, az, baz = gps2dist_azimuth(\n",
    "    lat1=event_location[1],\n",
    "    lon1=event_location[0],\n",
    "    lat2=station_location[1],\n",
    "    lon2=station_location[0])\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Calculate Theoretical Arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.taup import TauPyModel\n",
    "from obspy.geodetics import kilometers2degrees\n",
    "\n",
    "model = TauPyModel(model=\"iasp91\")\n",
    "arrivals = model.get_travel_times(\n",
    "    source_depth_in_km=cat[0].origins[0].depth / 1000,\n",
    "    distance_in_degree=kilometers2degrees(dist / 1000)\n",
    ")\n",
    "print(arrivals[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Calculate absolute time of the first arrivals at the station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_time_absolute = cat[0].origins[0].time + arrivals[0].time\n",
    "print(cat[0].origins[0].time)\n",
    "print(arrival_time_absolute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Cut to 1 minute before and 5 minutes after the first arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_new = st.copy()\n",
    "st_new.trim(\n",
    "    starttime=arrival_time_absolute - 60,\n",
    "    endtime= arrival_time_absolute + 300\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Remove the instrument response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_new.remove_response(inventory=inv, output=\"VEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Plot the resulting waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_new.plot()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Plot a map of the earthquake location, station location, and the great-circle path connecting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import pylab as plt\n",
    "\n",
    "projection = ccrs.PlateCarree()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\": projection})\n",
    "\n",
    "ax.coastlines()\n",
    "ax.set_global()\n",
    "ax.stock_img()\n",
    "ax.scatter(*station_location, marker=\"v\")\n",
    "ax.scatter(*event_location, marker=\"*\")\n",
    "\n",
    "ax.plot(\n",
    "    [event_location[0], station_location[0]],\n",
    "    [event_location[1], station_location[1]],\n",
    "    transform=ccrs.Geodetic()\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1052e4fc98c5d90ef93eee4c728ef1cf7dcd9893fcc0a92f26eae9c740ab6027"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
